{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science Project: Flight Delay Prediction: Big Data and Cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: this is a part of an exercise in CME 250A: Machine Learning with Big data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 1: Ask a question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My objective is, again, to the predict if a flight arrival is going to be delayed or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance is measured by AUC since it is a classification problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 2: Set the environment up and get data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, set up necessary computational tools. We use a tool for parallel computing called h2o. See instruction along the way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need Amazon Web Service. Get an account and if you are a student, get AWS educate so that you have some money to play with. Follow how to launch virtual machines (\"instances\") from this 10-Minute Tutorials: Launch a Linux Virtual Machine http://aws.amazon.com/s/dm/optimization/server-side-test/launch-a-virtual-machine-b/ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how to launch h2o on an EC2 instance. Note that you will get/see [.pem file] and [public ip] along the process of launching an instance.\n",
    "\n",
    "1. Open Git bash (right click on Desktop) and type $\\texttt{ssh -i ~/.ssh/[.pem file] -L 55555:localhost:54321 ec-2user@[ip]}$. This will get you through the ec2-user terminal. Then check java by typing $\\texttt{java -version}$.\n",
    "\n",
    "2. Open another Git bash window. Upload by using command $\\texttt{scp -i ~/.ssh/[.pem file] ~/h2o-3.8.2.2/h2o.jar ec2-user@[ip]:/home/ec2-user}$. Then launch h2o with command $\\texttt{java -jar h2o.jar}$\n",
    "\n",
    "3. To see the web interface of h2o. Go to URL: $\\texttt{localhost:55555/flow/index.html}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In this exercise, we need to use multiple clusters simulatenously to handle a big data set. We need to run a script given in class called 'python h2o-cluster-launch-instances.py'. It requires command called $\\texttt{bash}$ which is not natural in Windows. Hence, such a script needed to be run on a supportive terminal such as git shell. Here we integrate the script into this notebook. Hence, it is important that we initialize this notebook with command $\\texttt{ipython notebook}$ in git shell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import boto\n",
    "import boto.ec2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please aware that some variables need to be set according to AWS setup. See detail inside the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Environment variables you MUST set (either here or by passing them in).\n",
    "# -----------------------------------------------------------------------\n",
    "#\n",
    "# These keys are given during launching an instance process. It is a good practice to save both the .csv file (key + secret key info.\n",
    "# and the .pem file (ssh private key file) in the folder C:/User/Admin/.ssh/\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = '...'\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = '...'\n",
    "os.environ['AWS_SSH_PRIVATE_KEY_FILE'] = '..'\n",
    "\n",
    "# Launch EC2 instances with an IAM role\n",
    "# --------------------------------------\n",
    "# \n",
    "iam_profile_resource_name = None\n",
    "# or\n",
    "iam_profile_name = None\n",
    "\n",
    "# Options you MUST tailor to your own AWS account.\n",
    "# ------------------------------------------------\n",
    "\n",
    "# SSH key pair name. This should be consistent with keys above.\n",
    "#keyName = 'cliff click cme250a test key' \n",
    "keyName = 'Tee-h2o'   \n",
    "\n",
    "# AWS security group name. #You need to set this up in AWS and gives permission to all TCP and Anywhere. Go to the tab called\n",
    "#security group name. Set a new group and add two new rules: All TCP Anywhere and All UDP Anywhere.\n",
    "# Note:\n",
    "#     H2O uses TCP and UDP ports 54321 and 54322.\n",
    "#     RStudio uses TCP port 8787.\n",
    "#securityGroupName = 'h2o'\n",
    "securityGroupName = 'Tee-h2o'\n",
    "\n",
    "\n",
    "# Options you might want to change.\n",
    "# ---------------------------------\n",
    "# This is how to specify the number and the size of cluster. Try small things first\n",
    "\n",
    "numInstancesToLaunch = 4\n",
    "#numInstancesToLaunch = 1\n",
    "instanceType = 'm4.2xlarge'\n",
    "#instanceType = 't2.micro'\n",
    "instanceNameRoot = 'h2o-instance'\n",
    "\n",
    "\n",
    "# Options to help debugging.\n",
    "# --------------------------\n",
    "\n",
    "debug = 0\n",
    "# debug = 1\n",
    "dryRun = False\n",
    "# dryRun = True\n",
    "\n",
    "\n",
    "# Options you should not change unless you really mean to.\n",
    "# --------------------------------------------------------\n",
    "\n",
    "#regionName = 'us-east-1'\n",
    "#amiId = 'ami-0b100e61'\n",
    "\n",
    "regionName = 'us-west-1'\n",
    "amiId = 'ami-c1afd6a1'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are ready to call a group of instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using boto version 2.40.0\n",
      "Launching 4 instances.\n",
      "Waiting for instance 1 of 4 ...\n",
      "    .\n",
      "    .\n",
      "    .\n",
      "    .\n",
      "    .\n",
      "    .\n",
      "    .\n",
      "    .\n",
      "    .\n",
      "    .\n",
      "    .\n",
      "    .\n",
      "    .\n",
      "    .\n",
      "    .\n",
      "    .\n",
      "    .\n",
      "    instance 1 of 4 is up.\n",
      "Waiting for instance 2 of 4 ...\n",
      "    instance 2 of 4 is up.\n",
      "Waiting for instance 3 of 4 ...\n",
      "    instance 3 of 4 is up.\n",
      "Waiting for instance 4 of 4 ...\n",
      "    instance 4 of 4 is up.\n",
      "\n",
      "Creating output files:  nodes-public nodes-private\n",
      "\n",
      "Instance 1 of 4\n",
      "    Name:    h2o-instance0\n",
      "    PUBLIC:  ec2-54-67-81-81.us-west-1.compute.amazonaws.com\n",
      "    PRIVATE: 172.31.15.85\n",
      "\n",
      "Instance 2 of 4\n",
      "    Name:    h2o-instance1\n",
      "    PUBLIC:  ec2-54-153-122-120.us-west-1.compute.amazonaws.com\n",
      "    PRIVATE: 172.31.15.84\n",
      "\n",
      "Instance 3 of 4\n",
      "    Name:    h2o-instance2\n",
      "    PUBLIC:  ec2-54-153-31-38.us-west-1.compute.amazonaws.com\n",
      "    PRIVATE: 172.31.15.87\n",
      "\n",
      "Instance 4 of 4\n",
      "    Name:    h2o-instance3\n",
      "    PUBLIC:  ec2-54-183-182-145.us-west-1.compute.amazonaws.com\n",
      "    PRIVATE: 172.31.15.86\n",
      "\n",
      "Sleeping for 60 seconds for ssh to be available...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#--------------------------------------------------------------------------\n",
    "# No need to change anything below here.\n",
    "#--------------------------------------------------------------------------\n",
    "\n",
    "# Note: this python script was initially developed with boto 2.13.3.\n",
    "def botoVersionMismatch():\n",
    "    print 'WARNING:  Unsupported boto version.  Please upgrade boto to at least 2.13.x and try again.'\n",
    "    print 'Comment this out to run anyway.'\n",
    "    print 'Exiting.'\n",
    "    sys.exit(1)\n",
    "\n",
    "if not 'AWS_ACCESS_KEY_ID' in os.environ:\n",
    "    print 'ERROR: You must set AWS_ACCESS_KEY_ID in the environment.'\n",
    "    sys.exit(1)\n",
    "\n",
    "if not 'AWS_SECRET_ACCESS_KEY' in os.environ:\n",
    "    print 'ERROR: You must set AWS_SECRET_ACCESS_KEY in the environment.'\n",
    "    sys.exit(1)\n",
    "\n",
    "if not 'AWS_SSH_PRIVATE_KEY_FILE' in os.environ:\n",
    "    print 'ERROR: You must set AWS_SSH_PRIVATE_KEY_FILE in the environment.'\n",
    "    sys.exit(1)\n",
    "\n",
    "publicFileName = 'nodes-public'\n",
    "privateFileName = 'nodes-private'\n",
    "\n",
    "if not dryRun:\n",
    "    fpublic = open(publicFileName, 'w')\n",
    "    fprivate = open(privateFileName, 'w')\n",
    "\n",
    "print 'Using boto version', boto.Version\n",
    "if True:\n",
    "    botoVersionArr = boto.Version.split(\".\")\n",
    "    if (botoVersionArr[0] != 2):\n",
    "        botoVersionMismatch\n",
    "    if (botoVersionArr[1] < 13):\n",
    "        botoVersionMismatch\n",
    "\n",
    "if (debug):\n",
    "    boto.set_stream_logger('h2o-ec2')\n",
    "ec2 = boto.ec2.connect_to_region(regionName, debug=debug)\n",
    "\n",
    "print 'Launching', numInstancesToLaunch, 'instances.'\n",
    "\n",
    "reservation = ec2.run_instances(\n",
    "    image_id=amiId,\n",
    "    min_count=numInstancesToLaunch,\n",
    "    max_count=numInstancesToLaunch,\n",
    "    key_name=keyName,\n",
    "    instance_type=instanceType,\n",
    "    security_groups=[securityGroupName],\n",
    "    instance_profile_arn=iam_profile_resource_name,\n",
    "    instance_profile_name=iam_profile_name,\n",
    "    dry_run=dryRun\n",
    ")\n",
    "\n",
    "for i in range(numInstancesToLaunch):\n",
    "    instance = reservation.instances[i]\n",
    "    print 'Waiting for instance', i+1, 'of', numInstancesToLaunch, '...'\n",
    "    instance.update()\n",
    "    while instance.state != 'running':\n",
    "        print '    .'\n",
    "        time.sleep(1)\n",
    "        instance.update()\n",
    "    print '    instance', i+1, 'of', numInstancesToLaunch, 'is up.'\n",
    "    name = instanceNameRoot + str(i)\n",
    "    instance.add_tag('Name', value=name)\n",
    "\n",
    "print\n",
    "print 'Creating output files: ', publicFileName, privateFileName\n",
    "print\n",
    "\n",
    "for i in range(numInstancesToLaunch):\n",
    "    instance = reservation.instances[i]\n",
    "    instanceName = ''\n",
    "    if 'Name' in instance.tags:\n",
    "        instanceName = instance.tags['Name'];\n",
    "    print 'Instance', i+1, 'of', numInstancesToLaunch\n",
    "    print '    Name:   ', instanceName\n",
    "    print '    PUBLIC: ', instance.public_dns_name\n",
    "    print '    PRIVATE:', instance.private_ip_address\n",
    "    print\n",
    "    fpublic.write(instance.public_dns_name + '\\n')\n",
    "    fprivate.write(instance.private_ip_address + '\\n')\n",
    "\n",
    "fpublic.close()\n",
    "fprivate.close()\n",
    "os.system(\"dos2unix \"+publicFileName)\n",
    "os.system(\"dos2unix \"+privateFileName)\n",
    "\n",
    "print 'Sleeping for 60 seconds for ssh to be available...'\n",
    "time.sleep(60)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we put h2o into each instance. Note that we need to point to several in EC2_Scripts folder given in the class. Change the directory as appropriated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#d = os.path.dirname(os.path.realpath(__file__))\n",
    "#d = os.path.dirname(\"C:/Users/Admin/Documents/GitHub/DataSciencePortal/DataScienceTemplateAndProjects/\")\n",
    "d = os.path.dirname(\"C:/Users/Admin/Desktop/CME250A/EC2_Scripts/\")\n",
    "#d = os.path.dirname(\"C:/Users/Tee/Desktop/CME250A/EC2_Scripts/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing ssh access to instances...\n",
      "Distributing flatfile...\n",
      "Distributing AWS S3 credentials...\n",
      "Starting h2o cluster...\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To exit: use 'exit', 'quit', or Ctrl-D.\n"
     ]
    }
   ],
   "source": [
    "print 'Testing ssh access to instances...'\n",
    "cmd = d + '/' + 'h2o-cluster-test-ssh.sh'\n",
    "rv = os.system(\"bash \"+cmd)\n",
    "if rv != 0:\n",
    "    print 'Failed 1.'\n",
    "    sys.exit(1)\n",
    "\n",
    "print 'Distributing flatfile...'\n",
    "cmd = d + '/' + 'h2o-cluster-distribute-flatfile.sh'\n",
    "rv = os.system(\"bash \"+cmd)\n",
    "if rv != 0:\n",
    "    print 'Failed.'\n",
    "    sys.exit(1)\n",
    "\n",
    "print 'Distributing AWS S3 credentials...'\n",
    "cmd = d + '/' + 'h2o-cluster-distribute-aws-credentials.sh'\n",
    "rv = os.system(\"bash \"+cmd)\n",
    "if rv != 0:\n",
    "    print 'Failed.'\n",
    "    sys.exit(1)\n",
    "\n",
    "print 'Starting h2o cluster...'\n",
    "cmd = d + '/' + 'h2o-cluster-start-h2o.sh'\n",
    "rv = os.system(\"bash \"+cmd)\n",
    "if rv != 0:\n",
    "    print 'Failed.'\n",
    "    sys.exit(1)\n",
    "\n",
    "sys.exit(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, connect with h2o using one of the public IP in the cluster. You may see an error here if the H2O version of python and ones in the cluster do not match. Try to install python version to match. Once done, you can look up FLOW interface with http://[ip]:54321/flow/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime: </td>\n",
       "<td>46 seconds 976 milliseconds </td></tr>\n",
       "<tr><td>H2O cluster version: </td>\n",
       "<td>3.8.2.2</td></tr>\n",
       "<tr><td>H2O cluster name: </td>\n",
       "<td>H2ODemo</td></tr>\n",
       "<tr><td>H2O cluster total nodes: </td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O cluster total free memory: </td>\n",
       "<td>100.56 GB</td></tr>\n",
       "<tr><td>H2O cluster total cores: </td>\n",
       "<td>32</td></tr>\n",
       "<tr><td>H2O cluster allowed cores: </td>\n",
       "<td>32</td></tr>\n",
       "<tr><td>H2O cluster healthy: </td>\n",
       "<td>True</td></tr>\n",
       "<tr><td>H2O Connection ip: </td>\n",
       "<td>54.67.81.81</td></tr>\n",
       "<tr><td>H2O Connection port: </td>\n",
       "<td>54321</td></tr>\n",
       "<tr><td>H2O Connection proxy: </td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>Python Version: </td>\n",
       "<td>2.7.8</td></tr></table></div>"
      ],
      "text/plain": [
       "------------------------------  ---------------------------\n",
       "H2O cluster uptime:             46 seconds 976 milliseconds\n",
       "H2O cluster version:            3.8.2.2\n",
       "H2O cluster name:               H2ODemo\n",
       "H2O cluster total nodes:        4\n",
       "H2O cluster total free memory:  100.56 GB\n",
       "H2O cluster total cores:        32\n",
       "H2O cluster allowed cores:      32\n",
       "H2O cluster healthy:            True\n",
       "H2O Connection ip:              54.67.81.81\n",
       "H2O Connection port:            54321\n",
       "H2O Connection proxy:\n",
       "Python Version:                 2.7.8\n",
       "------------------------------  ---------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import h2o\n",
    "# Connect to h2o\n",
    "h2o.init(ip=\"54.67.81.81\") #public IP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I get data by setup Imports and Variables below. Note that the directory is different from the small data version as we need to access Amazon's S3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import and Parse flight data\n",
      "\n",
      "Parse Progress: [##################################################] 100%\n"
     ]
    }
   ],
   "source": [
    "# Load the weather data. We need it from S3 amazon set up for CME250A class.\n",
    "\n",
    "#path for a big flight data\n",
    "path = \"s3n://stanford-cme250a/allyears.csv\"\n",
    "#path = \"s3n://stanford-cme250a/allyears2k.csv\"\n",
    "\n",
    "print(\"Import and Parse flight data\")\n",
    "data = h2o.import_file(path=path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import and Parse weather data\n",
      "\n",
      "Parse Progress: [##################################################] 100%\n"
     ]
    }
   ],
   "source": [
    "# Load the weather data. We need it from S3 amazon set up for CME250A class.\n",
    "\n",
    "#Path for a big weather data\n",
    "path = \"s3n://stanford-cme250a/weather/data/\"\n",
    "\n",
    "#We only need from 1987 to 2008 to match flight data\n",
    "weather_years = [path+\"Xheader.csv\",\n",
    "                 path+\"X1987.csv\",\n",
    "                 path+\"X1988.csv\",\n",
    "                 path+\"X1989.csv\",\n",
    "                 path+\"X1990.csv\",\n",
    "                 path+\"X1991.csv\",\n",
    "                 path+\"X1992.csv\",\n",
    "                 path+\"X1993.csv\",\n",
    "                 path+\"X1994.csv\",\n",
    "                 path+\"X1995.csv\",\n",
    "                 path+\"X1996.csv\",\n",
    "                 path+\"X1997.csv\",\n",
    "                 path+\"X1998.csv\",\n",
    "                 path+\"X1999.csv\",\n",
    "                 path+\"X2000.csv\",\n",
    "                 path+\"X2001.csv\",\n",
    "                 path+\"X2002.csv\",\n",
    "                 path+\"X2003.csv\",\n",
    "                 path+\"X2004.csv\",\n",
    "                 path+\"X2005.csv\",\n",
    "                 path+\"X2006.csv\",\n",
    "                 path+\"X2007.csv\",\n",
    "                 path+\"X2008.csv\"]\n",
    "\n",
    "print(\"Import and Parse weather data\")\n",
    "wthr = h2o.import_file(path=weather_years)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to reformat this weather link file to work with the cluster. I don't know why it did not work in the first place. It is probably related to the double quote format of CSV file. A quick trick is to remove everything except two columns we need: iata_ref and maslib. Do it and save it as a new file called $\\texttt{master-location-identifier-database-20130801-reformatted.csv}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import and Parse airport/station link data\n",
      "\n",
      "Parse Progress: [##################################################] 100%\n"
     ]
    }
   ],
   "source": [
    "# Load the link data. The conversion between an airport name and a 6-digit Station code. This is local file. \n",
    "# This is a local file but downloadable from http://weather.noaa.gov/tg/site.shtml\n",
    "\n",
    "\n",
    "print(\"Import and Parse airport/station link data\")\n",
    "#Upload to S3 and import\n",
    "#path = \"s3n://tee-cme250a/master-location-identifier-database-20130801-reformatted.csv\"\n",
    "#airport_weather_link = h2o.import_file(path=path)\n",
    "\n",
    "#or upload locally\n",
    "path = \"C:/Users/Admin/Desktop/CME250A/weather/master-location-identifier-database-20130801-reformatted.csv\"\n",
    "airport_weather_link = h2o.upload_file(path=path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 3: Explore the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore, Visualize, Clean, Transform, Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, we will just follow the procedure as explain in the small data exercise. To see the detail of experimentation and choices of action. See the small data exercise. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flight data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Year, Month, DayOfMonth, integer is good. Leave it as it is. \n",
    "\n",
    "#DayOfWeek should be treated as enum instead of int\n",
    "data['DayOfWeek'] = data['DayOfWeek'].asfactor()\n",
    "\n",
    "#All Time should be converted to minutes (1 = 0*60+ 1, 2359 = 25*60+39)\n",
    "\n",
    "data = data.drop(\"DepTime\")\n",
    "data['CRSDepTime'] = (data['CRSDepTime']/100).floor()*60 + (data['CRSDepTime']%100)\n",
    "data = data.drop(\"ArrTime\")\n",
    "data['CRSArrTime'] = (data['CRSArrTime']/100).floor()*60 + (data['CRSArrTime']%100)\n",
    "\n",
    "#UniqueCarrier is good.\n",
    "\n",
    "#FlightNum should be treated as enum intead of int\n",
    "data['FlightNum'] = data['FlightNum'].asfactor()\n",
    "\n",
    "#ActualElapsedTime, CRSElapseTime, AirTime: keep only CRSElapseTime.\n",
    "data = data.drop(\"ActualElapsedTime\")\n",
    "data = data.drop(\"AirTime\")\n",
    "\n",
    "#ArrDelay, DepDelay are \"too good\" predictors. Drop it.\n",
    "data = data.drop(\"ArrDelay\").drop(\"DepDelay\")\n",
    "\n",
    "#Origin and Dest are good.\n",
    "\n",
    "#Cancelled, CancellationCode, Diverted, CarrierDelay, WeatherDelay, NASDelay, SecurityDelay, LateAircraftDelay are \"too good\" predictors. Drop it.\n",
    "data = data.drop(\"Cancelled\").drop(\"CancellationCode\").drop(\"Diverted\").drop(\"CarrierDelay\")\\\n",
    "    .drop(\"WeatherDelay\").drop(\"NASDelay\").drop(\"SecurityDelay\").drop(\"LateAircraftDelay\")\n",
    "    \n",
    "#Drop TaxiIn and TaxiOut? This is suspicious. So just drop it.\n",
    "data = data.drop(\"TaxiIn\").drop(\"TaxiOut\")\n",
    "\n",
    "#IsArrDelayed and IsDepDelayed should be treated as boolean. enum is fine.\n",
    "#Just focus on IsArrDelayed as in the lecture. Drop the other.\n",
    "data = data.drop(\"IsDepDelayed\")\n",
    "\n",
    "#Construct a proper date\n",
    "data[\"Date\"] = (data[\"Year\"]*10000) + (data[\"Month\"]*100) + data[\"DayofMonth\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Construct a proper date\n",
    "wthr[\"Date\"] = (wthr[\"Year\"]*10000) + wthr[\"MonthDay\"]\n",
    "\n",
    "#Select only relevant columns\n",
    "wthr = wthr[[\"Date\",\"Station\",\"temp\",\"sea level pres\",\"visibility\",\\\n",
    "               \"mean wind speed\",\"precipitation\",\"snow depth\",\"fog\",\"rain\",\"snow\",\"hail\",\"thunder\",\"tornado\"]]\n",
    "\n",
    "#Fix those columns with 9999.9 etc.\n",
    "wthr[wthr[\"Station\"]==999999.0,\"Station\"] = None\n",
    "wthr[wthr[\"sea level pres\"]==9999.9,\"sea level pres\"] = None\n",
    "wthr[wthr[\"visibility\"]==999.9,\"visibility\"] = None\n",
    "wthr[wthr[\"mean wind speed\"]==999.9,\"mean wind speed\"] = None\n",
    "wthr[wthr[\"precipitation\"]==99.99,\"precipitation\"] = None\n",
    "wthr[wthr[\"snow depth\"]==999.9,\"snow depth\"] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#remove data with Station info\n",
    "wthr2 = wthr[ wthr[\"Station\"] > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Airport/Weather station link data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#No need for this as we already have two columns of what we want.\n",
    "#airport_weather_link = airport_weather_link[['iata_xref','maslib']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Merging data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to small data scheme. We want to merge weather information at the destination airport at the same date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Let's connect with weather information on that day at the arrival airport. We know what is what since we reformat the weather link file.\n",
    "airport_weather_link.set_name(\"C1\",\"Dest\")\n",
    "airport_weather_link.set_name(\"C2\",\"Station\")\n",
    "\n",
    "#Merge with flight data\n",
    "data_with_link = data.merge(airport_weather_link,all_x=True,all_y=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59819229, 14)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wthr2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wthr_with_link = wthr2.merge(airport_weather_link,all_x=True,all_y=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wthr2 = wthr_with_link[~wthr_with_link[\"Dest\"].isna()]\n",
    "wthr2 = wthr2.drop(\"Dest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22198897, 14)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wthr2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Prune out more than half of weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create the feature to merge\n",
    "data_with_link[\"DateStation\"] = (data_with_link[\"Date\"]*1000000) + data_with_link[\"Station\"]\n",
    "data_with_link = data_with_link.drop(\"Station\") #Redundant information (similar to destination) \n",
    "data_with_link = data_with_link.drop(\"Date\") #Redundant "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create the feature to merge\n",
    "wthr2[\"DateStation\"] = (wthr2[\"Date\"]*1000000) + wthr2[\"Station\"]\n",
    "wthr2 = wthr2.drop(\"Station\").drop(\"Date\") # no longer needed these columns once merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((22198897, 12), (123534969, 14))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wthr2.shape, data_with_link.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#These are big tables. Difficult to merge. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-831dc116b10e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Merge data with DateStation key.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdata_with_weather\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_with_link\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwthr2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mall_x\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mall_y\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdata_with_weather\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_with_weather\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"DateStation\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#no longer need this link\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\Admin\\Anaconda\\lib\\site-packages\\h2o\\frame.pyc\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, i)\u001b[0m\n\u001b[0;32m   1182\u001b[0m       \u001b[0mH2OFrame\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[0mat\u001b[0m \u001b[0mindex\u001b[0m \u001b[0mi\u001b[0m \u001b[0mdropped\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mReturns\u001b[0m \u001b[0ma\u001b[0m \u001b[0mnew\u001b[0m \u001b[0mH2OFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1183\u001b[0m     \"\"\"\n\u001b[1;32m-> 1184\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1185\u001b[0m     \u001b[0mfr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mH2OFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_expr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexpr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mExprNode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"cols\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1186\u001b[0m     \u001b[0mfr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mncols\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Admin\\Anaconda\\lib\\site-packages\\h2o\\frame.pyc\u001b[0m in \u001b[0;36mnames\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnames_valid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Admin\\Anaconda\\lib\\site-packages\\h2o\\frame.pyc\u001b[0m in \u001b[0;36m_frame\u001b[1;34m(self, fill_cache)\u001b[0m\n\u001b[0;32m    423\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    424\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill_cache\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 425\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_eager_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    426\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfill_cache\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Admin\\Anaconda\\lib\\site-packages\\h2o\\expr.pyc\u001b[0m in \u001b[0;36m_eager_frame\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_empty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_id\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m  \u001b[1;31m# Data already computed under ID, but not cached locally\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_eval_driver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_eager_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# returns a scalar (or a list of scalars)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Admin\\Anaconda\\lib\\site-packages\\h2o\\expr.pyc\u001b[0m in \u001b[0;36m_eval_driver\u001b[1;34m(self, top)\u001b[0m\n\u001b[0;32m     81\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_eval_driver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[0mexec_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_it\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m     \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mExprNode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrapids\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexec_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;34m'scalar'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'scalar'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'scalar'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Admin\\Anaconda\\lib\\site-packages\\h2o\\expr.pyc\u001b[0m in \u001b[0;36mrapids\u001b[1;34m(expr)\u001b[0m\n\u001b[0;32m    163\u001b[0m       \u001b[0mThe\u001b[0m \u001b[0mJSON\u001b[0m \u001b[0mresponse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mas\u001b[0m \u001b[0ma\u001b[0m \u001b[0mpython\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[1;33m)\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mRapids\u001b[0m \u001b[0mexecution\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m     \"\"\"\n\u001b[1;32m--> 165\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mH2OConnection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpost_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Rapids\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mast\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexpr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msession_id\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mH2OConnection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msession_id\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_rest_version\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m99\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    166\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mASTId\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Admin\\Anaconda\\lib\\site-packages\\h2o\\connection.pyc\u001b[0m in \u001b[0;36mpost_json\u001b[1;34m(url_suffix, file_upload_info, **kwargs)\u001b[0m\n\u001b[0;32m    522\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m__H2OCONN__\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"No h2o connection. Did you run `h2o.init()` ?\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 524\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m__H2OCONN__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_rest_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl_suffix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"POST\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile_upload_info\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    525\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    526\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_rest_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl_suffix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile_upload_info\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Admin\\Anaconda\\lib\\site-packages\\h2o\\connection.pyc\u001b[0m in \u001b[0;36m_rest_json\u001b[1;34m(self, url_suffix, method, file_upload_info, **kwargs)\u001b[0m\n\u001b[0;32m    525\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    526\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_rest_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl_suffix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile_upload_info\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 527\u001b[1;33m     \u001b[0mraw_txt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_raw_rest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl_suffix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile_upload_info\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    528\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_tables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_txt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    529\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Admin\\Anaconda\\lib\\site-packages\\h2o\\connection.pyc\u001b[0m in \u001b[0;36m_do_raw_rest\u001b[1;34m(self, url_suffix, method, file_upload_info, **kwargs)\u001b[0m\n\u001b[0;32m    583\u001b[0m     \u001b[1;32mglobal\u001b[0m \u001b[0m_rest_ctr\u001b[0m\u001b[1;33m;\u001b[0m \u001b[0m_rest_ctr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_rest_ctr\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[0mbegin_time_seconds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 585\u001b[1;33m     \u001b[0mhttp_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_attempt_rest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpost_body\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile_upload_info\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    586\u001b[0m     \u001b[0mend_time_seconds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m     \u001b[0melapsed_time_seconds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mend_time_seconds\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mbegin_time_seconds\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Admin\\Anaconda\\lib\\site-packages\\h2o\\connection.pyc\u001b[0m in \u001b[0;36m_attempt_rest\u001b[1;34m(self, url, method, post_body, file_upload_info)\u001b[0m\n\u001b[0;32m    628\u001b[0m       \u001b[1;32melif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"POST\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    629\u001b[0m         \u001b[0mheaders\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Content-Type\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"application/x-www-form-urlencoded\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 630\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpost\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpost_body\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproxies\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_proxy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mauth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mauth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverify\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    631\u001b[0m       \u001b[1;32melif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"DELETE\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    632\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproxies\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_proxy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mauth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mauth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverify\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Admin\\Anaconda\\lib\\site-packages\\requests\\api.pyc\u001b[0m in \u001b[0;36mpost\u001b[1;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[0;32m    105\u001b[0m     \"\"\"\n\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 107\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'post'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Admin\\Anaconda\\lib\\site-packages\\requests\\api.pyc\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[1;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Admin\\Anaconda\\lib\\site-packages\\requests\\sessions.pyc\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    466\u001b[0m         }\n\u001b[0;32m    467\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 468\u001b[1;33m         \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    469\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    470\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Admin\\Anaconda\\lib\\site-packages\\requests\\sessions.pyc\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    574\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    575\u001b[0m         \u001b[1;31m# Send the request\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 576\u001b[1;33m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    577\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    578\u001b[0m         \u001b[1;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Admin\\Anaconda\\lib\\site-packages\\requests\\adapters.pyc\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    374\u001b[0m                     \u001b[0mdecode_content\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    375\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 376\u001b[1;33m                     \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    377\u001b[0m                 )\n\u001b[0;32m    378\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Admin\\Anaconda\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.pyc\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, **response_kw)\u001b[0m\n\u001b[0;32m    557\u001b[0m             httplib_response = self._make_request(conn, method, url,\n\u001b[0;32m    558\u001b[0m                                                   \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout_obj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 559\u001b[1;33m                                                   body=body, headers=headers)\n\u001b[0m\u001b[0;32m    560\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    561\u001b[0m             \u001b[1;31m# If we're going to release the connection in ``finally:``, then\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Admin\\Anaconda\\lib\\site-packages\\requests\\packages\\urllib3\\connectionpool.pyc\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    374\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    375\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Python 2.7, use buffering of HTTP responses\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 376\u001b[1;33m                 \u001b[0mhttplib_response\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    377\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Python 2.6 and older\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    378\u001b[0m                 \u001b[0mhttplib_response\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Admin\\Anaconda\\lib\\httplib.pyc\u001b[0m in \u001b[0;36mgetresponse\u001b[1;34m(self, buffering)\u001b[0m\n\u001b[0;32m   1065\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresponse_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1066\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1067\u001b[1;33m         \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1068\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwill_close\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0m_UNKNOWN\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1069\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_CS_IDLE\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Admin\\Anaconda\\lib\\httplib.pyc\u001b[0m in \u001b[0;36mbegin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    407\u001b[0m         \u001b[1;31m# read until we get a non-100 response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    408\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 409\u001b[1;33m             \u001b[0mversion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    410\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    411\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Admin\\Anaconda\\lib\\httplib.pyc\u001b[0m in \u001b[0;36m_read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    363\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m         \u001b[1;31m# Initialize with Simple-Response defaults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 365\u001b[1;33m         \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    366\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    367\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"header line\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Admin\\Anaconda\\lib\\socket.pyc\u001b[0m in \u001b[0;36mreadline\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    474\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    475\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 476\u001b[1;33m                     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_rbufsize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    477\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    478\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mEINTR\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Merge data with DateStation key.\n",
    "data_with_weather = data_with_link.merge(wthr2,all_x=True,all_y=False)\n",
    "data_with_weather = data_with_weather.drop(\"DateStation\") #no longer need this link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turned out that the merge process took too long (overnight). STOP HERE. This might be because the limitation of MERGE function in H2O."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below I outline the plan for the rest which is similar to the small data case. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 4: Model the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In term of preparing data for validation, it is done in the function split_fit_predict as defined below. It is modified such that the peformance measure is AUC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here four models are used: GBM (Gradient Boost Method) DRF (Distributed Random Forest) GLM (Generalized Linear Model) and Deep Learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_fit_predict(data):\n",
    "    global gbm0,drf0,glm0,dl0\n",
    "    # Classic Test/Train split\n",
    "    r = data['Year'].runif() # Random UNIForm numbers, one per row\n",
    "    train = data[ r < 0.7]\n",
    "    test = data[0.7 <= r]\n",
    "    print(\"Training data has\",train.ncol,\"columns and\",train.nrow,\"rows, test has\",test.nrow,\"rows\")\n",
    "    flight_names_x = data.names\n",
    "    if \"IsArrDelayed\" in flight_names_x: flight_names_x.remove(\"IsArrDelayed\")\n",
    "\n",
    "    # Run GBM\n",
    "    s = time.time()\n",
    "    gbm0 = h2o.H2OGradientBoostingEstimator(ntrees=400, max_depth=6, learn_rate=0.1)\n",
    "    gbm0.train(x=flight_names_x,y=\"IsArrDelayed\",training_frame =train,validation_frame=test)\n",
    "    gbm_elapsed = time.time() - s #measure elapse time\n",
    "\n",
    "    # Run DRF\n",
    "    s = time.time()\n",
    "    drf0 = h2o.H2ORandomForestEstimator(ntrees=100, max_depth=30)\n",
    "    drf0.train(x=flight_names_x,y=\"IsArrDelayed\",training_frame =train,validation_frame=test)\n",
    "    drf_elapsed = time.time() - s\n",
    "\n",
    "    # Run GLM\n",
    "    #if \"WC1\" in bike_names_x: bike_names_x.remove(\"WC1\")\n",
    "    s = time.time()\n",
    "    glm0 = h2o.H2OGeneralizedLinearEstimator(Lambda=[1e-5], family=\"binomial\") #For logistic\n",
    "    glm0.train(x=flight_names_x,y=\"IsArrDelayed\",training_frame =train,validation_frame=test)\n",
    "    glm_elapsed = time.time() - s\n",
    "\n",
    "    # Run DL\n",
    "    s = time.time()\n",
    "    dl0 = h2o.H2ODeepLearningEstimator(hidden=[50,50,50,50], epochs=6)\n",
    "    dl0.train(x=flight_names_x,y=\"IsArrDelayed\",training_frame =train,validation_frame=test)\n",
    "    dl_elapsed = time.time() - s\n",
    "\n",
    "    # ----------\n",
    "    # Score & report\n",
    "    header = [\"Model\", \"AUC TRAIN\", \"AUC TEST\", \"Model Training Time (s)\"]\n",
    "    table = [\n",
    "     [\"GBM\", gbm0.auc(train=True), gbm0.auc(valid=True),\n",
    "    round(gbm_elapsed,3)],\n",
    "     [\"DRF\", drf0.auc(train=True), drf0.auc(valid=True),\n",
    "    round(drf_elapsed,3)],\n",
    "     [\"GLM\", glm0.auc(train=True), glm0.auc(valid=True),\n",
    "    round(glm_elapsed,3)],\n",
    "     [\"DL \", dl0 .auc(train=True), dl0 .auc(valid=True),\n",
    "    round( dl_elapsed,3)],\n",
    "    ]\n",
    "    h2o.display.H2ODisplay(table,header)\n",
    "    # --------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Split the data (into test & train), fit some models and look at the results\n",
    "split_fit_predict(data)\n",
    "# Explore (in Flow) the 4 models - training time, quality of fit, tendency to overfit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's look at the model WITH weather information at the destination airport."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "split_fit_predict(data_with_weather)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By comparing results and checking model in H2O Flow (Go to http://[ip]:54321/flow/index.html Choose Model > List All Models). I found that the best performing model is xxx with weather information. Important features are Origin, Destination, and Flight number. It turns out that weather information is/ is not helpful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation is done implicitly when we look at H2O Flow models and train-test comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 5: Communicate the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For small data, I concluded that xxx with additional weather information is the best model with test AUC = 0.xxx. Weather information is/ is not helpful.\n",
    "\n",
    "Here is the performance visual.\n",
    "\n",
    "<img src=\"flight-delay-big-GBM-performance-1.JPG\" width = \"500x\">\n",
    "\n",
    "<img src=\"flight-delay-big-GBM-performance-2.JPG\" width = \"500x\">\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
